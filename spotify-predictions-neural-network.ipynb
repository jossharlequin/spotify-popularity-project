{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-12.428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>118.469</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>158.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.901</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>-28.454</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>83.972</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>282.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.604</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-19.924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>107.177</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>104.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-14.734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>108.003</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>180.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>-16.829</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>62.149</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>687.733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  energy  explicit  instrumentalness  key  \\\n",
       "0         0.995         0.708  0.1950         0             0.563   10   \n",
       "1         0.994         0.379  0.0135         0             0.901    8   \n",
       "2         0.604         0.749  0.2200         0             0.000    5   \n",
       "3         0.995         0.781  0.1300         0             0.887    1   \n",
       "4         0.990         0.210  0.2040         0             0.908   11   \n",
       "\n",
       "   liveness  loudness  mode  popularity  speechiness    tempo  valence  \\\n",
       "0    0.1510   -12.428     1           0       0.0506  118.469   0.7790   \n",
       "1    0.0763   -28.454     1           0       0.0462   83.972   0.0767   \n",
       "2    0.1190   -19.924     0           0       0.9290  107.177   0.8800   \n",
       "3    0.1110   -14.734     0           0       0.0926  108.003   0.7200   \n",
       "4    0.0980   -16.829     1           1       0.0424   62.149   0.0693   \n",
       "\n",
       "   duration_seconds  \n",
       "0           158.648  \n",
       "1           282.133  \n",
       "2           104.300  \n",
       "3           180.760  \n",
       "4           687.733  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the spotify data in from data.csv\n",
    "url = 'https://media.githubusercontent.com/media/jossharlequin/spotify-popularity-project/main/Resources/sql_spotify_data.csv'\n",
    "spotify_df = pd.read_csv(url)\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting popularity as the target variable and setting the remaining columns as features\n",
    "y = spotify_df.popularity.values\n",
    "X = spotify_df.drop(columns='popularity').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using StandarScaler as a preprocessing step for the neural network\n",
    "# Creating the StandardScalar instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the X data\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scaling the X data\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "# Splitting training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Binning the data based on data range \n",
    "bins = [-1, 50, 100]\n",
    "labels = [0, 1]\n",
    "y_train_binned = pd.cut(y_train, bins=bins, labels=labels)\n",
    "y_test_binned = pd.cut(y_test, bins=bins, labels=labels)\n",
    "\n",
    "# Encoding binned data into categorical data \n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_one_hot = encoder.fit_transform(y_train_binned.reshape(-1,1))\n",
    "y_test_one_hot = encoder.transform(y_test_binned.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4002 - accuracy: 0.8188\n",
      "Epoch 2/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3831 - accuracy: 0.8261\n",
      "Epoch 3/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3786 - accuracy: 0.8288\n",
      "Epoch 4/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3766 - accuracy: 0.8292\n",
      "Epoch 5/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3755 - accuracy: 0.8306\n",
      "Epoch 6/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3748 - accuracy: 0.8305\n",
      "Epoch 7/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3740 - accuracy: 0.8310\n",
      "Epoch 8/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3733 - accuracy: 0.8313\n",
      "Epoch 9/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3730 - accuracy: 0.8314\n",
      "Epoch 10/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3729 - accuracy: 0.8319\n",
      "Epoch 11/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3726 - accuracy: 0.8313\n",
      "Epoch 12/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3722 - accuracy: 0.8320\n",
      "Epoch 13/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3719 - accuracy: 0.8325\n",
      "Epoch 14/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3717 - accuracy: 0.8323\n",
      "Epoch 15/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3714 - accuracy: 0.8323\n",
      "Epoch 16/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3711 - accuracy: 0.8322\n",
      "Epoch 17/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3709 - accuracy: 0.8322\n",
      "Epoch 18/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3707 - accuracy: 0.8326\n",
      "Epoch 19/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3704 - accuracy: 0.8329\n",
      "Epoch 20/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3702 - accuracy: 0.8321\n",
      "Epoch 21/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3701 - accuracy: 0.8323\n",
      "Epoch 22/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3699 - accuracy: 0.8330\n",
      "Epoch 23/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3699 - accuracy: 0.8330\n",
      "Epoch 24/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3698 - accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3695 - accuracy: 0.8332\n",
      "Epoch 26/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3695 - accuracy: 0.8329\n",
      "Epoch 27/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3696 - accuracy: 0.8331\n",
      "Epoch 28/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3690 - accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3691 - accuracy: 0.8337\n",
      "Epoch 30/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3689 - accuracy: 0.8335\n",
      "Epoch 31/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3689 - accuracy: 0.8338\n",
      "Epoch 32/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3687 - accuracy: 0.8336\n",
      "Epoch 33/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3685 - accuracy: 0.8340\n",
      "Epoch 34/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3686 - accuracy: 0.8340\n",
      "Epoch 35/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3686 - accuracy: 0.8335\n",
      "Epoch 36/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3684 - accuracy: 0.8337\n",
      "Epoch 37/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3682 - accuracy: 0.8336\n",
      "Epoch 38/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3682 - accuracy: 0.8339\n",
      "Epoch 39/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3681 - accuracy: 0.8341\n",
      "Epoch 40/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3680 - accuracy: 0.8336\n",
      "Epoch 41/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3681 - accuracy: 0.8338\n",
      "Epoch 42/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3678 - accuracy: 0.8338\n",
      "Epoch 43/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3678 - accuracy: 0.8338\n",
      "Epoch 44/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3675 - accuracy: 0.8341\n",
      "Epoch 45/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3676 - accuracy: 0.8337\n",
      "Epoch 46/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3675 - accuracy: 0.8339\n",
      "Epoch 47/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3677 - accuracy: 0.8338\n",
      "Epoch 48/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3675 - accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8337\n",
      "Epoch 50/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3674 - accuracy: 0.8339\n",
      "Epoch 51/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8342\n",
      "Epoch 52/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8340\n",
      "Epoch 53/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8335\n",
      "Epoch 54/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8341\n",
      "Epoch 55/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3672 - accuracy: 0.8345\n",
      "Epoch 56/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3672 - accuracy: 0.8341\n",
      "Epoch 57/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3672 - accuracy: 0.8341\n",
      "Epoch 58/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3671 - accuracy: 0.8345\n",
      "Epoch 59/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3670 - accuracy: 0.8346\n",
      "Epoch 60/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3670 - accuracy: 0.8343\n",
      "Epoch 61/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3668 - accuracy: 0.8343\n",
      "Epoch 62/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3669 - accuracy: 0.8344\n",
      "Epoch 63/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3668 - accuracy: 0.8343\n",
      "Epoch 64/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3670 - accuracy: 0.8347\n",
      "Epoch 65/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3667 - accuracy: 0.8345\n",
      "Epoch 66/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3667 - accuracy: 0.8342\n",
      "Epoch 67/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3666 - accuracy: 0.8341\n",
      "Epoch 68/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3666 - accuracy: 0.8345\n",
      "Epoch 69/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3666 - accuracy: 0.8345\n",
      "Epoch 70/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3665 - accuracy: 0.8348\n",
      "Epoch 71/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3664 - accuracy: 0.8349\n",
      "Epoch 72/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3664 - accuracy: 0.8348\n",
      "Epoch 73/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3665 - accuracy: 0.8349\n",
      "Epoch 74/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3664 - accuracy: 0.8351\n",
      "Epoch 75/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3664 - accuracy: 0.8350\n",
      "Epoch 76/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3662 - accuracy: 0.8353\n",
      "Epoch 77/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3664 - accuracy: 0.8349\n",
      "Epoch 78/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3663 - accuracy: 0.8344\n",
      "Epoch 79/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3661 - accuracy: 0.8349\n",
      "Epoch 80/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3662 - accuracy: 0.8348\n",
      "Epoch 81/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3661 - accuracy: 0.8347\n",
      "Epoch 82/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3660 - accuracy: 0.8347\n",
      "Epoch 83/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3661 - accuracy: 0.8347\n",
      "Epoch 84/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3659 - accuracy: 0.8349\n",
      "Epoch 85/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3659 - accuracy: 0.8343\n",
      "Epoch 86/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8347\n",
      "Epoch 87/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3660 - accuracy: 0.8347\n",
      "Epoch 88/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3659 - accuracy: 0.8349\n",
      "Epoch 89/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8345\n",
      "Epoch 90/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8345\n",
      "Epoch 91/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8347\n",
      "Epoch 92/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8342\n",
      "Epoch 93/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8342\n",
      "Epoch 94/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3656 - accuracy: 0.8347\n",
      "Epoch 95/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3656 - accuracy: 0.8349\n",
      "Epoch 96/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3656 - accuracy: 0.8346\n",
      "Epoch 97/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3657 - accuracy: 0.8346\n",
      "Epoch 98/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3654 - accuracy: 0.8346\n",
      "Epoch 99/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3656 - accuracy: 0.8346\n",
      "Epoch 100/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3654 - accuracy: 0.8349\n",
      "1328/1328 - 2s - loss: 0.3723 - accuracy: 0.8352 - 2s/epoch - 1ms/step\n",
      "Loss: 0.37226295471191406, Accuracy: 0.8351852893829346\n",
      "1328/1328 [==============================] - 2s 2ms/step\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>31659</td>\n",
       "      <td>1809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>5192</td>\n",
       "      <td>3818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0        31659         1809\n",
       "Actual 1         5192         3818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8351852723762889\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     33468\n",
      "           1       0.68      0.42      0.52      9010\n",
      "\n",
      "    accuracy                           0.84     42478\n",
      "   macro avg       0.77      0.68      0.71     42478\n",
      "weighted avg       0.82      0.84      0.82     42478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\", input_dim=13))\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "fit_model = nn_model.fit(X_train, y_train_one_hot, epochs=100)\n",
    "\n",
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Finding predicted y classes\n",
    "y_predicted = nn_model.predict(X_test)\n",
    "\n",
    "# Converting y_predicted and y_test_one_hot into integer values for confusion matrix and accuracy score\n",
    "y_test_classes = np.argmax(y_test_one_hot, axis=1)\n",
    "y_predicted_classes = np.argmax(y_predicted, axis=1)\n",
    "\n",
    "# Creating confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_predicted_classes)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=['Actual 0','Actual 1'], columns=['Predicted 0','Predicted 1']\n",
    ")\n",
    "\n",
    "# Creating accuracy score\n",
    "acc_score = accuracy_score(y_test_classes, y_predicted_classes)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score: {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_classes, y_predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Binning the data into equal sized groups\n",
    "labels=[0,1]\n",
    "q_binned_data = pd.qcut(spotify_df['popularity'], 2, labels=labels, precision=0)\n",
    "\n",
    "# Scaling the data using StandarScaler as a preprocessing step for the neural network\n",
    "# Creating the StandardScalar instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the X data\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scaling the X data\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "# Splitting training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, q_binned_data, random_state=42)\n",
    "\n",
    "# Convert y_train and y_test from Pandas Series to NumPy arrays\n",
    "y_train_np = np.array(y_train).reshape(-1, 1)\n",
    "y_test_np = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "# Encoding binned data into categorical data\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_one_hot = encoder.fit_transform(y_train_np)\n",
    "y_test_one_hot = encoder.transform(y_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4746 - accuracy: 0.7682\n",
      "Epoch 2/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4513 - accuracy: 0.7813\n",
      "Epoch 3/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4475 - accuracy: 0.7816\n",
      "Epoch 4/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4454 - accuracy: 0.7833\n",
      "Epoch 5/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4441 - accuracy: 0.7835\n",
      "Epoch 6/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4430 - accuracy: 0.7850\n",
      "Epoch 7/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4419 - accuracy: 0.7847\n",
      "Epoch 8/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4410 - accuracy: 0.7853\n",
      "Epoch 9/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4405 - accuracy: 0.7862\n",
      "Epoch 10/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4397 - accuracy: 0.7860\n",
      "Epoch 11/50\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4394 - accuracy: 0.7855\n",
      "Epoch 12/50\n",
      "3983/3983 [==============================] - 10s 3ms/step - loss: 0.4392 - accuracy: 0.7866\n",
      "Epoch 13/50\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4391 - accuracy: 0.7868\n",
      "Epoch 14/50\n",
      "3983/3983 [==============================] - 10s 3ms/step - loss: 0.4383 - accuracy: 0.7868\n",
      "Epoch 15/50\n",
      "3983/3983 [==============================] - 10s 3ms/step - loss: 0.4381 - accuracy: 0.7871\n",
      "Epoch 16/50\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4379 - accuracy: 0.7869\n",
      "Epoch 17/50\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4375 - accuracy: 0.7862\n",
      "Epoch 18/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4375 - accuracy: 0.7868\n",
      "Epoch 19/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4372 - accuracy: 0.7875\n",
      "Epoch 20/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4372 - accuracy: 0.7873\n",
      "Epoch 21/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4371 - accuracy: 0.7879\n",
      "Epoch 22/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4370 - accuracy: 0.7877\n",
      "Epoch 23/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4365 - accuracy: 0.7878\n",
      "Epoch 24/50\n",
      "3983/3983 [==============================] - 10s 3ms/step - loss: 0.4365 - accuracy: 0.7873\n",
      "Epoch 25/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4361 - accuracy: 0.7876\n",
      "Epoch 26/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4361 - accuracy: 0.7880\n",
      "Epoch 27/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4359 - accuracy: 0.7881\n",
      "Epoch 28/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4357 - accuracy: 0.7880\n",
      "Epoch 29/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4358 - accuracy: 0.7879\n",
      "Epoch 30/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4355 - accuracy: 0.7880\n",
      "Epoch 31/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4354 - accuracy: 0.7885\n",
      "Epoch 32/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4351 - accuracy: 0.7882\n",
      "Epoch 33/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4354 - accuracy: 0.7877\n",
      "Epoch 34/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4352 - accuracy: 0.7879\n",
      "Epoch 35/50\n",
      "3983/3983 [==============================] - 14s 3ms/step - loss: 0.4350 - accuracy: 0.7884\n",
      "Epoch 36/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4352 - accuracy: 0.7878\n",
      "Epoch 37/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4350 - accuracy: 0.7881\n",
      "Epoch 38/50\n",
      "3983/3983 [==============================] - 14s 4ms/step - loss: 0.4347 - accuracy: 0.7883\n",
      "Epoch 39/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4346 - accuracy: 0.7883\n",
      "Epoch 40/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4345 - accuracy: 0.7889\n",
      "Epoch 41/50\n",
      "3983/3983 [==============================] - 12s 3ms/step - loss: 0.4344 - accuracy: 0.7885\n",
      "Epoch 42/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4345 - accuracy: 0.7877\n",
      "Epoch 43/50\n",
      "3983/3983 [==============================] - 14s 3ms/step - loss: 0.4342 - accuracy: 0.7879\n",
      "Epoch 44/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4344 - accuracy: 0.7886\n",
      "Epoch 45/50\n",
      "3983/3983 [==============================] - 14s 3ms/step - loss: 0.4346 - accuracy: 0.7885\n",
      "Epoch 46/50\n",
      "3983/3983 [==============================] - 13s 3ms/step - loss: 0.4344 - accuracy: 0.7885\n",
      "Epoch 47/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4340 - accuracy: 0.7885\n",
      "Epoch 48/50\n",
      "3983/3983 [==============================] - 18s 5ms/step - loss: 0.4343 - accuracy: 0.7889\n",
      "Epoch 49/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4340 - accuracy: 0.7893\n",
      "Epoch 50/50\n",
      "3983/3983 [==============================] - 11s 3ms/step - loss: 0.4338 - accuracy: 0.7885\n",
      "1328/1328 - 3s - loss: 0.4379 - accuracy: 0.7874 - 3s/epoch - 2ms/step\n",
      "Loss: 0.43791937828063965, Accuracy: 0.7874193787574768\n",
      "1328/1328 [==============================] - 3s 2ms/step\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>16957</td>\n",
       "      <td>4151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>4879</td>\n",
       "      <td>16491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0        16957         4151\n",
       "Actual 1         4879        16491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7874193700268374\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79     21108\n",
      "           1       0.80      0.77      0.79     21370\n",
      "\n",
      "    accuracy                           0.79     42478\n",
      "   macro avg       0.79      0.79      0.79     42478\n",
      "weighted avg       0.79      0.79      0.79     42478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\", input_dim=13))\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "fit_model = nn_model.fit(X_train, y_train_one_hot, epochs=50)\n",
    "\n",
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Finding predicted y classes\n",
    "y_predicted = nn_model.predict(X_test)\n",
    "\n",
    "# Converting y_predicted and y_test_one_hot into integer values for confusion matrix and accuracy score\n",
    "y_test_classes = np.argmax(y_test_one_hot, axis=1)\n",
    "y_predicted_classes = np.argmax(y_predicted, axis=1)\n",
    "\n",
    "# Creating confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_predicted_classes)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=['Actual 0','Actual 1'], columns=['Predicted 0','Predicted 1']\n",
    ")\n",
    "\n",
    "# Creating accuracy score\n",
    "acc_score = accuracy_score(y_test_classes, y_predicted_classes)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score: {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_classes, y_predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
