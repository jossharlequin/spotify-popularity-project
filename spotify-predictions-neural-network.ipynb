{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-12.428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>118.469</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>158.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.901</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>-28.454</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>83.972</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>282.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.604</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-19.924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>107.177</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>104.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-14.734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>108.003</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>180.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>-16.829</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>62.149</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>687.733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  energy  explicit  instrumentalness  key  \\\n",
       "0         0.995         0.708  0.1950         0             0.563   10   \n",
       "1         0.994         0.379  0.0135         0             0.901    8   \n",
       "2         0.604         0.749  0.2200         0             0.000    5   \n",
       "3         0.995         0.781  0.1300         0             0.887    1   \n",
       "4         0.990         0.210  0.2040         0             0.908   11   \n",
       "\n",
       "   liveness  loudness  mode  popularity  speechiness    tempo  valence  \\\n",
       "0    0.1510   -12.428     1           0       0.0506  118.469   0.7790   \n",
       "1    0.0763   -28.454     1           0       0.0462   83.972   0.0767   \n",
       "2    0.1190   -19.924     0           0       0.9290  107.177   0.8800   \n",
       "3    0.1110   -14.734     0           0       0.0926  108.003   0.7200   \n",
       "4    0.0980   -16.829     1           1       0.0424   62.149   0.0693   \n",
       "\n",
       "   duration_seconds  \n",
       "0           158.648  \n",
       "1           282.133  \n",
       "2           104.300  \n",
       "3           180.760  \n",
       "4           687.733  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the spotify data in from data.csv\n",
    "url = 'https://media.githubusercontent.com/media/jossharlequin/spotify-popularity-project/main/Resources/sql_spotify_data.csv'\n",
    "spotify_df = pd.read_csv(url)\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting popularity as the target variable and setting the remaining columns as features\n",
    "y = spotify_df.popularity.values\n",
    "X = spotify_df.drop(columns='popularity').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using StandarScaler as a preprocessing step for the neural network\n",
    "# Creating the StandardScalar instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the X data\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scaling the X data\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "# Splitting training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Binning the target variable into groups based  \n",
    "bins = [-1, 50, 100]\n",
    "labels = [0, 1]\n",
    "y_train_binned = pd.cut(y_train, bins=bins, labels=labels)\n",
    "y_test_binned = pd.cut(y_test, bins=bins, labels=labels)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_one_hot = encoder.fit_transform(y_train_binned.reshape(-1,1))\n",
    "y_test_one_hot = encoder.transform(y_test_binned.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4002 - accuracy: 0.8188\n",
      "Epoch 2/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3831 - accuracy: 0.8261\n",
      "Epoch 3/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3786 - accuracy: 0.8288\n",
      "Epoch 4/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3766 - accuracy: 0.8292\n",
      "Epoch 5/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3755 - accuracy: 0.8306\n",
      "Epoch 6/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3748 - accuracy: 0.8305\n",
      "Epoch 7/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3740 - accuracy: 0.8310\n",
      "Epoch 8/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3733 - accuracy: 0.8313\n",
      "Epoch 9/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3730 - accuracy: 0.8314\n",
      "Epoch 10/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3729 - accuracy: 0.8319\n",
      "Epoch 11/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3726 - accuracy: 0.8313\n",
      "Epoch 12/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3722 - accuracy: 0.8320\n",
      "Epoch 13/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3719 - accuracy: 0.8325\n",
      "Epoch 14/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3717 - accuracy: 0.8323\n",
      "Epoch 15/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3714 - accuracy: 0.8323\n",
      "Epoch 16/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3711 - accuracy: 0.8322\n",
      "Epoch 17/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3709 - accuracy: 0.8322\n",
      "Epoch 18/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3707 - accuracy: 0.8326\n",
      "Epoch 19/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3704 - accuracy: 0.8329\n",
      "Epoch 20/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3702 - accuracy: 0.8321\n",
      "Epoch 21/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3701 - accuracy: 0.8323\n",
      "Epoch 22/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3699 - accuracy: 0.8330\n",
      "Epoch 23/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3699 - accuracy: 0.8330\n",
      "Epoch 24/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3698 - accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3695 - accuracy: 0.8332\n",
      "Epoch 26/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3695 - accuracy: 0.8329\n",
      "Epoch 27/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3696 - accuracy: 0.8331\n",
      "Epoch 28/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3690 - accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3691 - accuracy: 0.8337\n",
      "Epoch 30/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3689 - accuracy: 0.8335\n",
      "Epoch 31/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3689 - accuracy: 0.8338\n",
      "Epoch 32/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3687 - accuracy: 0.8336\n",
      "Epoch 33/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3685 - accuracy: 0.8340\n",
      "Epoch 34/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3686 - accuracy: 0.8340\n",
      "Epoch 35/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3686 - accuracy: 0.8335\n",
      "Epoch 36/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3684 - accuracy: 0.8337\n",
      "Epoch 37/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3682 - accuracy: 0.8336\n",
      "Epoch 38/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3682 - accuracy: 0.8339\n",
      "Epoch 39/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3681 - accuracy: 0.8341\n",
      "Epoch 40/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3680 - accuracy: 0.8336\n",
      "Epoch 41/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3681 - accuracy: 0.8338\n",
      "Epoch 42/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3678 - accuracy: 0.8338\n",
      "Epoch 43/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3678 - accuracy: 0.8338\n",
      "Epoch 44/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3675 - accuracy: 0.8341\n",
      "Epoch 45/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3676 - accuracy: 0.8337\n",
      "Epoch 46/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3675 - accuracy: 0.8339\n",
      "Epoch 47/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3677 - accuracy: 0.8338\n",
      "Epoch 48/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3675 - accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8337\n",
      "Epoch 50/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3674 - accuracy: 0.8339\n",
      "Epoch 51/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8342\n",
      "Epoch 52/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8340\n",
      "Epoch 53/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8335\n",
      "Epoch 54/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3673 - accuracy: 0.8341\n",
      "Epoch 55/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3672 - accuracy: 0.8345\n",
      "Epoch 56/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3672 - accuracy: 0.8341\n",
      "Epoch 57/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3672 - accuracy: 0.8341\n",
      "Epoch 58/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3671 - accuracy: 0.8345\n",
      "Epoch 59/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3670 - accuracy: 0.8346\n",
      "Epoch 60/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3670 - accuracy: 0.8343\n",
      "Epoch 61/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3668 - accuracy: 0.8343\n",
      "Epoch 62/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3669 - accuracy: 0.8344\n",
      "Epoch 63/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3668 - accuracy: 0.8343\n",
      "Epoch 64/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3670 - accuracy: 0.8347\n",
      "Epoch 65/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3667 - accuracy: 0.8345\n",
      "Epoch 66/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3667 - accuracy: 0.8342\n",
      "Epoch 67/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3666 - accuracy: 0.8341\n",
      "Epoch 68/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3666 - accuracy: 0.8345\n",
      "Epoch 69/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3666 - accuracy: 0.8345\n",
      "Epoch 70/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3665 - accuracy: 0.8348\n",
      "Epoch 71/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3664 - accuracy: 0.8349\n",
      "Epoch 72/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3664 - accuracy: 0.8348\n",
      "Epoch 73/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3665 - accuracy: 0.8349\n",
      "Epoch 74/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3664 - accuracy: 0.8351\n",
      "Epoch 75/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3664 - accuracy: 0.8350\n",
      "Epoch 76/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3662 - accuracy: 0.8353\n",
      "Epoch 77/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3664 - accuracy: 0.8349\n",
      "Epoch 78/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3663 - accuracy: 0.8344\n",
      "Epoch 79/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3661 - accuracy: 0.8349\n",
      "Epoch 80/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3662 - accuracy: 0.8348\n",
      "Epoch 81/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3661 - accuracy: 0.8347\n",
      "Epoch 82/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3660 - accuracy: 0.8347\n",
      "Epoch 83/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3661 - accuracy: 0.8347\n",
      "Epoch 84/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3659 - accuracy: 0.8349\n",
      "Epoch 85/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3659 - accuracy: 0.8343\n",
      "Epoch 86/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8347\n",
      "Epoch 87/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3660 - accuracy: 0.8347\n",
      "Epoch 88/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3659 - accuracy: 0.8349\n",
      "Epoch 89/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8345\n",
      "Epoch 90/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8345\n",
      "Epoch 91/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8347\n",
      "Epoch 92/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8342\n",
      "Epoch 93/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3658 - accuracy: 0.8342\n",
      "Epoch 94/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3656 - accuracy: 0.8347\n",
      "Epoch 95/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3656 - accuracy: 0.8349\n",
      "Epoch 96/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3656 - accuracy: 0.8346\n",
      "Epoch 97/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3657 - accuracy: 0.8346\n",
      "Epoch 98/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3654 - accuracy: 0.8346\n",
      "Epoch 99/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.3656 - accuracy: 0.8346\n",
      "Epoch 100/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.3654 - accuracy: 0.8349\n",
      "1328/1328 - 2s - loss: 0.3723 - accuracy: 0.8352 - 2s/epoch - 1ms/step\n",
      "Loss: 0.37226295471191406, Accuracy: 0.8351852893829346\n",
      "1328/1328 [==============================] - 2s 2ms/step\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>31659</td>\n",
       "      <td>1809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>5192</td>\n",
       "      <td>3818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0        31659         1809\n",
       "Actual 1         5192         3818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8351852723762889\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     33468\n",
      "           1       0.68      0.42      0.52      9010\n",
      "\n",
      "    accuracy                           0.84     42478\n",
      "   macro avg       0.77      0.68      0.71     42478\n",
      "weighted avg       0.82      0.84      0.82     42478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\", input_dim=13))\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=15, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "fit_model = nn_model.fit(X_train, y_train_one_hot, epochs=100)\n",
    "\n",
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Finding predicted y classes\n",
    "y_predicted = nn_model.predict(X_test)\n",
    "\n",
    "# Converting y_predicted and y_test_one_hot into integer values for confusion matrix and accuracy score\n",
    "y_test_classes = np.argmax(y_test_one_hot, axis=1)\n",
    "y_predicted_classes = np.argmax(y_predicted, axis=1)\n",
    "\n",
    "# Creating confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_predicted_classes)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=['Actual 0','Actual 1'], columns=['Predicted 0','Predicted 1']\n",
    ")\n",
    "\n",
    "# Creating accuracy score\n",
    "acc_score = accuracy_score(y_test_classes, y_predicted_classes)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score: {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_classes, y_predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Binning the data into quintiles based on number of samples per group instead of absolute values that the data falls into\n",
    "labels=[0,1]\n",
    "q_binned_data = pd.qcut(spotify_df['popularity'], 2, labels=labels, precision=0)\n",
    "\n",
    "display(type(q_binned_data))\n",
    "\n",
    "# Scaling the data using StandarScaler as a preprocessing step for the neural network\n",
    "# Creating the StandardScalar instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the X data\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scaling the X data\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "# Splitting training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, q_binned_data, random_state=42)\n",
    "\n",
    "# Convert y_train and y_test from Pandas Series to NumPy arrays\n",
    "y_train_np = np.array(y_train).reshape(-1, 1)\n",
    "y_test_np = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_one_hot = encoder.fit_transform(y_train_np)\n",
    "y_test_one_hot = encoder.transform(y_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4694 - accuracy: 0.7710\n",
      "Epoch 2/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4505 - accuracy: 0.7803\n",
      "Epoch 3/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4460 - accuracy: 0.7822\n",
      "Epoch 4/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4434 - accuracy: 0.7839\n",
      "Epoch 5/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4421 - accuracy: 0.7856\n",
      "Epoch 6/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4407 - accuracy: 0.7858\n",
      "Epoch 7/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4397 - accuracy: 0.7855\n",
      "Epoch 8/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4389 - accuracy: 0.7859\n",
      "Epoch 9/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4384 - accuracy: 0.7868\n",
      "Epoch 10/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4375 - accuracy: 0.7870\n",
      "Epoch 11/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4373 - accuracy: 0.7869\n",
      "Epoch 12/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4367 - accuracy: 0.7872\n",
      "Epoch 13/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4363 - accuracy: 0.7869\n",
      "Epoch 14/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4358 - accuracy: 0.7880\n",
      "Epoch 15/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4355 - accuracy: 0.7878\n",
      "Epoch 16/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4352 - accuracy: 0.7877\n",
      "Epoch 17/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4347 - accuracy: 0.7886\n",
      "Epoch 18/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4345 - accuracy: 0.7878\n",
      "Epoch 19/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4343 - accuracy: 0.7883\n",
      "Epoch 20/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4344 - accuracy: 0.7881\n",
      "Epoch 21/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4339 - accuracy: 0.7887\n",
      "Epoch 22/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4337 - accuracy: 0.7885\n",
      "Epoch 23/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4335 - accuracy: 0.7893\n",
      "Epoch 24/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4335 - accuracy: 0.7889\n",
      "Epoch 25/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4330 - accuracy: 0.7891\n",
      "Epoch 26/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4332 - accuracy: 0.7890\n",
      "Epoch 27/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4329 - accuracy: 0.7889\n",
      "Epoch 28/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4325 - accuracy: 0.7889\n",
      "Epoch 29/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4326 - accuracy: 0.7889\n",
      "Epoch 30/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4325 - accuracy: 0.7891\n",
      "Epoch 31/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4322 - accuracy: 0.7895\n",
      "Epoch 32/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4322 - accuracy: 0.7896\n",
      "Epoch 33/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4318 - accuracy: 0.7899\n",
      "Epoch 34/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4320 - accuracy: 0.7899\n",
      "Epoch 35/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4317 - accuracy: 0.7896\n",
      "Epoch 36/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4315 - accuracy: 0.7899\n",
      "Epoch 37/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4316 - accuracy: 0.7903\n",
      "Epoch 38/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4313 - accuracy: 0.7899\n",
      "Epoch 39/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4313 - accuracy: 0.7896\n",
      "Epoch 40/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4310 - accuracy: 0.7902\n",
      "Epoch 41/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4308 - accuracy: 0.7900\n",
      "Epoch 42/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4307 - accuracy: 0.7901\n",
      "Epoch 43/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4306 - accuracy: 0.7899\n",
      "Epoch 44/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4308 - accuracy: 0.7893\n",
      "Epoch 45/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4306 - accuracy: 0.7902\n",
      "Epoch 46/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4307 - accuracy: 0.7907\n",
      "Epoch 47/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4305 - accuracy: 0.7903\n",
      "Epoch 48/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4303 - accuracy: 0.7900\n",
      "Epoch 49/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4299 - accuracy: 0.7908\n",
      "Epoch 50/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4300 - accuracy: 0.7907\n",
      "Epoch 51/100\n",
      "3983/3983 [==============================] - 10s 3ms/step - loss: 0.4299 - accuracy: 0.7911\n",
      "Epoch 52/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4299 - accuracy: 0.7912\n",
      "Epoch 53/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4296 - accuracy: 0.7909\n",
      "Epoch 54/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4299 - accuracy: 0.7907\n",
      "Epoch 55/100\n",
      "3983/3983 [==============================] - 10s 3ms/step - loss: 0.4294 - accuracy: 0.7909\n",
      "Epoch 56/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4295 - accuracy: 0.7910\n",
      "Epoch 57/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4292 - accuracy: 0.7905\n",
      "Epoch 58/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4294 - accuracy: 0.7917\n",
      "Epoch 59/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4294 - accuracy: 0.7907\n",
      "Epoch 60/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4292 - accuracy: 0.7910\n",
      "Epoch 61/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4293 - accuracy: 0.7914\n",
      "Epoch 62/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4289 - accuracy: 0.7921\n",
      "Epoch 63/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4288 - accuracy: 0.7911\n",
      "Epoch 64/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4289 - accuracy: 0.7915\n",
      "Epoch 65/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4289 - accuracy: 0.7915\n",
      "Epoch 66/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4288 - accuracy: 0.7913\n",
      "Epoch 67/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4289 - accuracy: 0.7914\n",
      "Epoch 68/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4288 - accuracy: 0.7913\n",
      "Epoch 69/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4285 - accuracy: 0.7912\n",
      "Epoch 70/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4287 - accuracy: 0.7912\n",
      "Epoch 71/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4286 - accuracy: 0.7918\n",
      "Epoch 72/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4284 - accuracy: 0.7913\n",
      "Epoch 73/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4282 - accuracy: 0.7914\n",
      "Epoch 74/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4283 - accuracy: 0.7911\n",
      "Epoch 75/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4284 - accuracy: 0.7913\n",
      "Epoch 76/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4283 - accuracy: 0.7916\n",
      "Epoch 77/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4285 - accuracy: 0.7911\n",
      "Epoch 78/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4282 - accuracy: 0.7915\n",
      "Epoch 79/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4280 - accuracy: 0.7917\n",
      "Epoch 80/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4279 - accuracy: 0.7921\n",
      "Epoch 81/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4277 - accuracy: 0.7921\n",
      "Epoch 82/100\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 0.4278 - accuracy: 0.7919\n",
      "Epoch 83/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4278 - accuracy: 0.7920\n",
      "Epoch 84/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4276 - accuracy: 0.7919\n",
      "Epoch 85/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4278 - accuracy: 0.7916\n",
      "Epoch 86/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4276 - accuracy: 0.7921\n",
      "Epoch 87/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4279 - accuracy: 0.7920\n",
      "Epoch 88/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4274 - accuracy: 0.7921\n",
      "Epoch 89/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4275 - accuracy: 0.7922\n",
      "Epoch 90/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4277 - accuracy: 0.7920\n",
      "Epoch 91/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4274 - accuracy: 0.7919\n",
      "Epoch 92/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4273 - accuracy: 0.7919\n",
      "Epoch 93/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4273 - accuracy: 0.7928\n",
      "Epoch 94/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4274 - accuracy: 0.7926\n",
      "Epoch 95/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4271 - accuracy: 0.7925\n",
      "Epoch 96/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4273 - accuracy: 0.7922\n",
      "Epoch 97/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4271 - accuracy: 0.7923\n",
      "Epoch 98/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4272 - accuracy: 0.7924\n",
      "Epoch 99/100\n",
      "3983/3983 [==============================] - 10s 2ms/step - loss: 0.4269 - accuracy: 0.7919\n",
      "Epoch 100/100\n",
      "3983/3983 [==============================] - 9s 2ms/step - loss: 0.4271 - accuracy: 0.7922\n",
      "1328/1328 - 2s - loss: 0.4386 - accuracy: 0.7870 - 2s/epoch - 1ms/step\n",
      "Loss: 0.4386175870895386, Accuracy: 0.7870191335678101\n",
      "1328/1328 [==============================] - 2s 2ms/step\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>16427</td>\n",
       "      <td>4681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>4366</td>\n",
       "      <td>17004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0        16427         4681\n",
       "Actual 1         4366        17004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.787019162860775\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78     21108\n",
      "           1       0.78      0.80      0.79     21370\n",
      "\n",
      "    accuracy                           0.79     42478\n",
      "   macro avg       0.79      0.79      0.79     42478\n",
      "weighted avg       0.79      0.79      0.79     42478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=18, activation=\"relu\", input_dim=13))\n",
    "nn_model.add(tf.keras.layers.Dense(units=18, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=18, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=18, activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "fit_model = nn_model.fit(X_train, y_train_one_hot, epochs=100)\n",
    "\n",
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Finding predicted y classes\n",
    "y_predicted = nn_model.predict(X_test)\n",
    "\n",
    "# Converting y_predicted and y_test_one_hot into integer values for confusion matrix and accuracy score\n",
    "y_test_classes = np.argmax(y_test_one_hot, axis=1)\n",
    "y_predicted_classes = np.argmax(y_predicted, axis=1)\n",
    "\n",
    "# Creating confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_predicted_classes)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=['Actual 0','Actual 1'], columns=['Predicted 0','Predicted 1']\n",
    ")\n",
    "\n",
    "# Creating accuracy score\n",
    "acc_score = accuracy_score(y_test_classes, y_predicted_classes)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score: {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_classes, y_predicted_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
