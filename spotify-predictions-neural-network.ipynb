{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995</td>\n",
       "      <td>['Carl Woitschach']</td>\n",
       "      <td>0.708</td>\n",
       "      <td>158648</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0</td>\n",
       "      <td>6KbQ3uYMLKb5jDxLF7wYDD</td>\n",
       "      <td>0.563</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-12.428</td>\n",
       "      <td>1</td>\n",
       "      <td>Singende Bataillone 1. Teil</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>118.469</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994</td>\n",
       "      <td>['Robert Schumann', 'Vladimir Horowitz']</td>\n",
       "      <td>0.379</td>\n",
       "      <td>282133</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0</td>\n",
       "      <td>6KuQTIu1KoTTkLXKrwlLPV</td>\n",
       "      <td>0.901</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>-28.454</td>\n",
       "      <td>1</td>\n",
       "      <td>Fantasiestücke, Op. 111: Più tosto lento</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>83.972</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.604</td>\n",
       "      <td>['Seweryn Goszczyński']</td>\n",
       "      <td>0.749</td>\n",
       "      <td>104300</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0</td>\n",
       "      <td>6L63VW0PibdM1HDSBoqnoM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-19.924</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 1.18 - Zamek kaniowski</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>107.177</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995</td>\n",
       "      <td>['Francisco Canaro']</td>\n",
       "      <td>0.781</td>\n",
       "      <td>180760</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0</td>\n",
       "      <td>6M94FkXd15sOAOQYRnWPN8</td>\n",
       "      <td>0.887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-14.734</td>\n",
       "      <td>0</td>\n",
       "      <td>Bebamos Juntos - Instrumental (Remasterizado)</td>\n",
       "      <td>0</td>\n",
       "      <td>1928-09-25</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>108.003</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990</td>\n",
       "      <td>['Frédéric Chopin', 'Vladimir Horowitz']</td>\n",
       "      <td>0.210</td>\n",
       "      <td>687733</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0</td>\n",
       "      <td>6N6tiFZ9vLTSOIxkj8qKrd</td>\n",
       "      <td>0.908</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>-16.829</td>\n",
       "      <td>1</td>\n",
       "      <td>Polonaise-Fantaisie in A-Flat Major, Op. 61</td>\n",
       "      <td>1</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>62.149</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness                                   artists  danceability  \\\n",
       "0         0.995                       ['Carl Woitschach']         0.708   \n",
       "1         0.994  ['Robert Schumann', 'Vladimir Horowitz']         0.379   \n",
       "2         0.604                   ['Seweryn Goszczyński']         0.749   \n",
       "3         0.995                      ['Francisco Canaro']         0.781   \n",
       "4         0.990  ['Frédéric Chopin', 'Vladimir Horowitz']         0.210   \n",
       "\n",
       "   duration_ms  energy  explicit                      id  instrumentalness  \\\n",
       "0       158648  0.1950         0  6KbQ3uYMLKb5jDxLF7wYDD             0.563   \n",
       "1       282133  0.0135         0  6KuQTIu1KoTTkLXKrwlLPV             0.901   \n",
       "2       104300  0.2200         0  6L63VW0PibdM1HDSBoqnoM             0.000   \n",
       "3       180760  0.1300         0  6M94FkXd15sOAOQYRnWPN8             0.887   \n",
       "4       687733  0.2040         0  6N6tiFZ9vLTSOIxkj8qKrd             0.908   \n",
       "\n",
       "   key  liveness  loudness  mode  \\\n",
       "0   10    0.1510   -12.428     1   \n",
       "1    8    0.0763   -28.454     1   \n",
       "2    5    0.1190   -19.924     0   \n",
       "3    1    0.1110   -14.734     0   \n",
       "4   11    0.0980   -16.829     1   \n",
       "\n",
       "                                            name  popularity release_date  \\\n",
       "0                    Singende Bataillone 1. Teil           0         1928   \n",
       "1       Fantasiestücke, Op. 111: Più tosto lento           0         1928   \n",
       "2                 Chapter 1.18 - Zamek kaniowski           0         1928   \n",
       "3  Bebamos Juntos - Instrumental (Remasterizado)           0   1928-09-25   \n",
       "4    Polonaise-Fantaisie in A-Flat Major, Op. 61           1         1928   \n",
       "\n",
       "   speechiness    tempo  valence  year  \n",
       "0       0.0506  118.469   0.7790  1928  \n",
       "1       0.0462   83.972   0.0767  1928  \n",
       "2       0.9290  107.177   0.8800  1928  \n",
       "3       0.0926  108.003   0.7200  1928  \n",
       "4       0.0424   62.149   0.0693  1928  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the spotify data in from data.csv\n",
    "url = 'https://media.githubusercontent.com/media/jossharlequin/spotify-popularity-project/main/Resources/data.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169909 entries, 0 to 169908\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   acousticness      169909 non-null  float64\n",
      " 1   danceability      169909 non-null  float64\n",
      " 2   duration_ms       169909 non-null  int64  \n",
      " 3   energy            169909 non-null  float64\n",
      " 4   explicit          169909 non-null  int64  \n",
      " 5   instrumentalness  169909 non-null  float64\n",
      " 6   key               169909 non-null  int64  \n",
      " 7   liveness          169909 non-null  float64\n",
      " 8   loudness          169909 non-null  float64\n",
      " 9   mode              169909 non-null  int64  \n",
      " 10  popularity        169909 non-null  int64  \n",
      " 11  speechiness       169909 non-null  float64\n",
      " 12  tempo             169909 non-null  float64\n",
      " 13  valence           169909 non-null  float64\n",
      " 14  seconds           169909 non-null  float64\n",
      "dtypes: float64(10), int64(5)\n",
      "memory usage: 19.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop unused columns\n",
    "spotify_df = df.drop(columns=['artists', 'name', 'id', 'release_date', 'year'])\n",
    "spotify_df['seconds'] = spotify_df['duration_ms']/1000\n",
    "# spotify_df.info()\n",
    "spotify_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting popularity as the target variable and setting the remaining columns as features\n",
    "y = spotify_df.popularity.values\n",
    "X = spotify_df.drop(columns='popularity').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using StandarScaler as a preprocessing step for the neural network\n",
    "# Creating the StandardScalar instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting the X data\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scaling the X data\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "# Splitting training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Converting the target variable to one-hot encoded format\u001b[39;00m\n\u001b[0;32m      8\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[1;32m----> 9\u001b[0m y_train_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_binned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m y_test_one_hot \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(y_test_binned, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\np_utils.py:74\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     72\u001b[0m n \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     73\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n, num_classes), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m---> 74\u001b[0m categorical[np\u001b[38;5;241m.\u001b[39marange(n), y] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     75\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[0;32m     76\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "# Binning the target variable into 10 groups  \n",
    "bins = [-1, 20, 40, 60, 80, 100]\n",
    "labels = [0, 2, 4, 6, 8]\n",
    "y_train_binned = pd.cut(y_train, bins=bins, labels=labels)\n",
    "y_test_binned = pd.cut(y_test, bins=bins, labels=labels)\n",
    "\n",
    "# Converting the target variable to one-hot encoded format\n",
    "num_classes = len(labels)\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train_binned, num_classes=num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test_binned, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\josep\\anaconda3\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras-tuner) (3.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: rich in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: optree in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\josep\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from optree->keras->keras-tuner) (4.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "\n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=100,\n",
    "        step=2), activation=activation, input_dim=14))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 10)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=100,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=10,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the kerastuner search for best hyperparameters\n",
    "tuner.search(X_train, y_train_one_hot, epochs=10, validation_data=(X_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.5894 - accuracy: 0.3872\n",
      "Epoch 2/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.5162 - accuracy: 0.4051\n",
      "Epoch 3/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.5040 - accuracy: 0.4066\n",
      "Epoch 4/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4968 - accuracy: 0.4083\n",
      "Epoch 5/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4934 - accuracy: 0.4085\n",
      "Epoch 6/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4915 - accuracy: 0.4092\n",
      "Epoch 7/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4899 - accuracy: 0.4086\n",
      "Epoch 8/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4886 - accuracy: 0.4102\n",
      "Epoch 9/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4878 - accuracy: 0.4103\n",
      "Epoch 10/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4867 - accuracy: 0.4104\n",
      "1328/1328 - 2s - loss: 1.4873 - accuracy: 0.4127 - 2s/epoch - 1ms/step\n",
      "Loss: 1.4873112440109253, Accuracy: 0.4126606583595276\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\", input_dim=14))\n",
    "nn_model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "fit_model = nn_model.fit(X_train, y_train_one_hot, epochs=10)\n",
    "\n",
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.6019 - accuracy: 0.3850\n",
      "Epoch 2/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.5209 - accuracy: 0.4044\n",
      "Epoch 3/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.5089 - accuracy: 0.4082\n",
      "Epoch 4/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.5017 - accuracy: 0.4087\n",
      "Epoch 5/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4969 - accuracy: 0.4096\n",
      "Epoch 6/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4937 - accuracy: 0.4101\n",
      "Epoch 7/10\n",
      "3983/3983 [==============================] - 6s 2ms/step - loss: 1.4912 - accuracy: 0.4107\n",
      "Epoch 8/10\n",
      "3983/3983 [==============================] - 6s 2ms/step - loss: 1.4890 - accuracy: 0.4113\n",
      "Epoch 9/10\n",
      "3983/3983 [==============================] - 6s 2ms/step - loss: 1.4868 - accuracy: 0.4106\n",
      "Epoch 10/10\n",
      "3983/3983 [==============================] - 6s 2ms/step - loss: 1.4852 - accuracy: 0.4121\n",
      "1328/1328 - 2s - loss: 1.4837 - accuracy: 0.4144 - 2s/epoch - 1ms/step\n",
      "Loss: 1.4837090969085693, Accuracy score: 0.4144027531147003\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"tanh\", input_dim=14))\n",
    "nn_model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "fit_model = nn_model.fit(X_train, y_train_one_hot, epochs=10)\n",
    "\n",
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy score: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.5423 - accuracy: 0.3982\n",
      "Epoch 2/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4907 - accuracy: 0.4099\n",
      "Epoch 3/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4773 - accuracy: 0.4121\n",
      "Epoch 4/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4697 - accuracy: 0.4151\n",
      "Epoch 5/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4645 - accuracy: 0.4154\n",
      "Epoch 6/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4608 - accuracy: 0.4160\n",
      "Epoch 7/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4576 - accuracy: 0.4169\n",
      "Epoch 8/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4550 - accuracy: 0.4181\n",
      "Epoch 9/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4534 - accuracy: 0.4187\n",
      "Epoch 10/10\n",
      "3983/3983 [==============================] - 7s 2ms/step - loss: 1.4504 - accuracy: 0.4194\n",
      "1328/1328 - 2s - loss: 1.4570 - accuracy: 0.4164 - 2s/epoch - 1ms/step\n",
      "Loss: 1.4569848775863647, Accuracy: 0.41638025641441345\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=50, activation=\"tanh\", input_dim=14))\n",
    "nn_model.add(tf.keras.layers.Dense(units=50, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "fit_model = nn_model.fit(X_train, y_train_one_hot, epochs=10)\n",
    "\n",
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.5283 - accuracy: 0.4006\n",
      "Epoch 2/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4837 - accuracy: 0.4093\n",
      "Epoch 3/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4713 - accuracy: 0.4136\n",
      "Epoch 4/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4637 - accuracy: 0.4152\n",
      "Epoch 5/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4584 - accuracy: 0.4177\n",
      "Epoch 6/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4531 - accuracy: 0.4200\n",
      "Epoch 7/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4499 - accuracy: 0.4211\n",
      "Epoch 8/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4471 - accuracy: 0.4212\n",
      "Epoch 9/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4443 - accuracy: 0.4210\n",
      "Epoch 10/10\n",
      "3983/3983 [==============================] - 8s 2ms/step - loss: 1.4425 - accuracy: 0.4227\n",
      "1328/1328 - 2s - loss: 1.4517 - accuracy: 0.4210 - 2s/epoch - 1ms/step\n",
      "Loss: 1.4517264366149902, Accuracy: 0.42104148864746094\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=50, activation=\"tanh\", input_dim=14))\n",
    "nn_model.add(tf.keras.layers.Dense(units=50, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=50, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "# Compile the sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "fit_model = nn_model.fit(X_train, y_train_one_hot, epochs=10)\n",
    "\n",
    "# Evaluating the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
